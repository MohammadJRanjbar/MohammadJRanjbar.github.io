<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ParsVoice - Persian Zero-Shot TTS Demo</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: #ffffff;
            color: #1a1a1a;
            line-height: 1.6;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 60px 20px;
            text-align: center;
        }
        .header h1 {
            font-size: 3em;
            font-weight: 700;
            margin-bottom: 15px;
            letter-spacing: -0.5px;
        }
        .header .subtitle {
            font-size: 1.4em;
            font-weight: 300;
            opacity: 0.95;
            margin-bottom: 10px;
        }
        .header .description {
            font-size: 1.1em;
            opacity: 0.85;
            max-width: 800px;
            margin: 20px auto 0;
        }
        .paper-section {
            background: linear-gradient(to bottom, #f8f9fa 0%, #ffffff 100%);
            padding: 50px 20px;
            border-bottom: 1px solid #e0e0e0;
        }
        .paper-container {
            max-width: 1000px;
            margin: 0 auto;
        }
        .citation-box {
            background: white;
            border-radius: 16px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.1);
            padding: 40px;
            margin-bottom: 40px;
            border-left: 6px solid #667eea;
        }
        .citation-header {
            display: flex;
            align-items: center;
            gap: 15px;
            margin-bottom: 25px;
        }
        .citation-icon {
            font-size: 2.5em;
        }
        .citation-header h2 {
            font-size: 1.8em;
            color: #2c3e50;
            font-weight: 700;
        }
        .paper-title {
            font-size: 1.4em;
            font-weight: 700;
            color: #667eea;
            margin-bottom: 15px;
            line-height: 1.4;
        }
        .paper-authors {
            font-size: 1.1em;
            color: #555;
            margin-bottom: 8px;
        }
        .paper-institution {
            font-size: 1em;
            color: #777;
            margin-bottom: 25px;
        }
        .paper-links {
            display: flex;
            gap: 15px;
            flex-wrap: wrap;
            margin-top: 25px;
            padding-top: 25px;
            border-top: 2px solid #f0f0f0;
        }
        .paper-link {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 12px 24px;
            border-radius: 8px;
            text-decoration: none;
            font-weight: 600;
            font-size: 0.95em;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
        }
        .paper-link:hover {
            transform: translateY(-3px);
            box-shadow: 0 6px 25px rgba(102, 126, 234, 0.4);
        }
        .bibtex-box {
            background: #2c3e50;
            color: #e8e8e8;
            padding: 25px;
            border-radius: 12px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            line-height: 1.8;
            overflow-x: auto;
            margin-top: 20px;
            box-shadow: inset 0 2px 10px rgba(0,0,0,0.2);
        }
        .bibtex-box code {
            color: #a8dadc;
        }
        .about-section {
            background: white;
            border-radius: 16px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.1);
            padding: 40px;
            margin-top: 30px;
        }
        .about-header {
            display: flex;
            align-items: center;
            gap: 15px;
            margin-bottom: 25px;
        }
        .about-icon {
            font-size: 2.5em;
        }
        .about-header h3 {
            font-size: 1.6em;
            color: #2c3e50;
            font-weight: 700;
        }
        .about-content {
            font-size: 1.05em;
            color: #444;
            line-height: 1.9;
            text-align: justify;
        }
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }
        .stat-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 12px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.2);
        }
        .stat-number {
            font-size: 2.2em;
            font-weight: 700;
            margin-bottom: 8px;
        }
        .stat-label {
            font-size: 0.95em;
            opacity: 0.9;
        }
        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 60px 20px;
        }
        .intro {
            text-align: center;
            margin-bottom: 60px;
        }
        .intro h2 {
            font-size: 2.2em;
            color: #2c3e50;
            margin-bottom: 15px;
            font-weight: 600;
        }
        .intro p {
            font-size: 1.15em;
            color: #555;
            max-width: 700px;
            margin: 0 auto;
        }
        .samples-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(450px, 1fr));
            gap: 40px;
            margin-top: 40px;
        }
        .sample-card {
            background: white;
            border: 1px solid #e0e0e0;
            border-radius: 12px;
            padding: 30px;
            transition: all 0.3s ease;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        }
        .sample-card:hover {
            box-shadow: 0 8px 24px rgba(0,0,0,0.12);
            transform: translateY(-2px);
        }
        .sample-header {
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 2px solid #f0f0f0;
        }
        .sample-number {
            font-size: 0.9em;
            color: #667eea;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        .transcript {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            border-left: 4px solid #667eea;
        }
        .transcript-label {
            font-size: 0.85em;
            color: #667eea;
            font-weight: 600;
            margin-bottom: 8px;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        .transcript-text {
            font-size: 1.05em;
            color: #2c3e50;
            direction: rtl;
            text-align: right;
            line-height: 1.8;
        }
        .audio-section {
            margin-bottom: 25px;
        }
        .audio-label {
            font-size: 0.95em;
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 10px;
            display: block;
        }
        audio {
            width: 100%;
            height: 40px;
            outline: none;
        }
        audio::-webkit-media-controls-panel {
            background-color: #f8f9fa;
        }
        .loading {
            text-align: center;
            padding: 60px 20px;
            font-size: 1.3em;
            color: #667eea;
        }
        .error {
            background: #fee;
            color: #c33;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
            margin: 40px auto;
            max-width: 600px;
            border: 1px solid #fcc;
        }
        .speaker-info {
            display: inline-block;
            background: #f0f0f0;
            padding: 6px 14px;
            border-radius: 20px;
            font-size: 0.9em;
            color: #555;
            margin-top: 10px;
        }
        @media (max-width: 768px) {
            .header h1 {
                font-size: 2em;
            }
            .header .subtitle {
                font-size: 1.1em;
            }
            .samples-grid {
                grid-template-columns: 1fr;
            }
            .intro h2 {
                font-size: 1.6em;
            }
            .citation-box, .about-section {
                padding: 25px;
            }
            .paper-title {
                font-size: 1.2em;
            }
            .paper-links {
                flex-direction: column;
            }
            .paper-link {
                width: 100%;
                justify-content: center;
            }
            .stats-grid {
                grid-template-columns: 1fr;
            }
        }
        footer {
            background: #2c3e50;
            color: white;
            text-align: center;
            padding: 30px 20px;
            margin-top: 80px;
        }
        footer p {
            opacity: 0.8;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>ParsVoice</h1>
        <div class="subtitle">First Persian Zero-Shot Text-to-Speech Model</div>
        <div class="description">
            The largest high-quality Persian speech dataset with 1,804 hours of clean audio from 470+ speakers
        </div>
    </div>

    <div class="paper-section">
        <div class="paper-container">
            <div class="citation-box">
                <div class="citation-header">
                    <span class="citation-icon">ðŸ“„</span>
                    <h2>Research Paper</h2>
                </div>
                <div class="paper-title">ParsVoice: A Large-Scale Multi-Speaker Persian Speech Corpus for Text-to-Speech Synthesis</div>
                <div class="paper-authors">Mohammad Javad Ranjbar Kalahroodi, Heshaam Faili, Azadeh Shakery</div>
                <div class="paper-institution">University of Tehran</div>
                
                <div class="bibtex-box">
<code>@article{ranjbar2024parsvoice,
  title={ParsVoice: A Large-Scale Multi-Speaker Persian Speech Corpus for Text-to-Speech Synthesis},
  author={Ranjbar Kalahroodi, Mohammad Javad and Faili, Heshaam and Shakery, Azadeh},
  journal={arXiv preprint arXiv:2510.10774},
  year={2024}
}</code>
                </div>

                <div class="paper-links">
                    <a href="https://arxiv.org/pdf/2510.10774" target="_blank" class="paper-link">
                        <span>ðŸ“‘</span> Read Full Paper
                    </a>
                    <a href="https://huggingface.co/datasets/MohammadJRanjbar/ParsVoice" target="_blank" class="paper-link">
                        <span>ðŸ¤—</span> Access Dataset
                    </a>
                </div>
            </div>

            <div class="about-section">
                <div class="about-header">
                    <span class="about-icon">ðŸ’¡</span>
                    <h3>About ParsVoice</h3>
                </div>
                <div class="about-content">
                    Existing Persian speech datasets are typically smaller than their English counterparts, which creates a key limitation for developing Persian speech technologies. We address this gap by introducing ParsVoice, the largest Persian speech corpus designed specifically for text-to-speech (TTS) applications. We created an automated pipeline that transforms raw audiobook content into TTS-ready data, incorporating components such as a BERT-based sentence completion detector, a binary search boundary optimization method for precise audio-text alignment, and audio-text quality assessment frameworks tailored to Persian. The pipeline processes 2,000 audiobooks, yielding 3,526 hours of clean speech, which was further filtered into a 1,804-hour high-quality subset suitable for TTS, featuring more than 470 speakers. To validate the dataset, we fine-tuned XTTS for Persian, achieving a naturalness Mean Opinion Score (MOS) of 3.6/5 and a Speaker Similarity Mean Opinion Score (SMOS) of 4.0/5, demonstrating ParsVoice's effectiveness for training multi-speaker TTS systems. ParsVoice is the largest high-quality Persian speech dataset, offering speaker diversity and audio quality comparable to major English corpora. The complete dataset has been made publicly available to accelerate the development of Persian speech technologies.
                </div>

                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number">1,804h</div>
                        <div class="stat-label">High-Quality Audio</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">470+</div>
                        <div class="stat-label">Speakers</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">3.6/5</div>
                        <div class="stat-label">Naturalness (MOS)</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">4.0/5</div>
                        <div class="stat-label">Speaker Similarity</div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="container">
        <div class="intro">
            <h2>Sample Demonstrations</h2>
            <p>Listen to high-quality synthesized speech samples generated by our zero-shot TTS model</p>
        </div>
        <div id="loading" class="loading">Loading samples...</div>
        <div id="error" style="display: none;"></div>
        <div class="samples-grid" id="samplesGrid"></div>
    </div>

    <footer>
        <p>&copy; 2025 ParsVoice - University of Tehran</p>
    </footer>

    <script>
        async function loadSamples() {
            try {
                const response = await fetch('best_speeches.json');
                if (!response.ok) throw new Error('Failed to load data');
                
                const samples = await response.json();
                
                document.getElementById('loading').style.display = 'none';
                
                if (samples.length === 0) {
                    document.getElementById('error').innerHTML = '<div class="error">No samples available at this time.</div>';
                    document.getElementById('error').style.display = 'block';
                    return;
                }
                
                displaySamples(samples);
            } catch (error) {
                console.error('Error loading samples:', error);
                document.getElementById('loading').style.display = 'none';
                document.getElementById('error').innerHTML = '<div class="error">Error loading samples. Please ensure best_speeches.json is in the same directory.</div>';
                document.getElementById('error').style.display = 'block';
            }
        }
        function displaySamples(samples) {
            const grid = document.getElementById('samplesGrid');
            
            samples.forEach((sample, index) => {
                const card = document.createElement('div');
                card.className = 'sample-card';
                
                const genderLabel = sample.speaker_gender === 'M' ? 'Male' : 'Female';
                
                card.innerHTML = `
                    <div class="sample-header">
                        <div class="sample-number">Sample ${index + 1}</div>
                        <div class="speaker-info">${genderLabel} Speaker</div>
                    </div>
                    
                    <div class="transcript">
                        <div class="transcript-label">Transcript</div>
                        <div class="transcript-text">${sample.transcript}</div>
                    </div>
                    
                    <div class="audio-section">
                        <label class="audio-label">Reference Audio</label>
                        <audio controls preload="none">
                            <source src="${sample.reference_audio}" type="audio/wav">
                            <source src="${sample.reference_audio}" type="audio/mpeg">
                            Your browser does not support the audio element.
                        </audio>
                    </div>
                    
                    <div class="audio-section">
                        <label class="audio-label">Generated Audio</label>
                        <audio controls preload="none">
                            <source src="${sample.generated_audio}" type="audio/wav">
                            <source src="${sample.generated_audio}" type="audio/mpeg">
                            Your browser does not support the audio element.
                        </audio>
                    </div>
                `;
                
                grid.appendChild(card);
            });
        }
        document.addEventListener('DOMContentLoaded', loadSamples);
    </script>
</body>
</html>
